{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "225611eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install ipympl\n",
    "# %matplotlib inline\n",
    "import platform\n",
    "import os\n",
    "import ipympl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import bisect\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from scipy.stats import zscore\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5cf539d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_boc():\n",
    "    '''\n",
    "    Initialises and returns the BrainObservatoryCache\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    BrainObservatoryCache : allensdk.core.brain_observatory_nwb_data_set.BrainObservatoryNwbDataSet\n",
    "    '''\n",
    "    \n",
    "    # Set file location based on platform. \n",
    "    platstring = platform.platform()\n",
    "    if ('Darwin' in platstring) or ('macOS' in platstring):\n",
    "        # macOS \n",
    "        data_root = \"/Volumes/TReND2024/\"\n",
    "    elif 'Windows'  in platstring:\n",
    "        # Windows (replace with the drive letter of USB drive)\n",
    "        data_root = \"E:/\"\n",
    "    elif ('amzn' in platstring):\n",
    "        # then on Code Ocean\n",
    "        data_root = \"/data/\"\n",
    "    else:\n",
    "        # then your own linux platform\n",
    "        # EDIT location where you mounted hard drive\n",
    "        data_root = \"/media/$USERNAME/TReND2024/\"\n",
    "\n",
    "    from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "\n",
    "    manifest_file = os.path.join(data_root,'allen-brain-observatory/visual-coding-2p/manifest.json')\n",
    "\n",
    "    return BrainObservatoryCache(manifest_file=manifest_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78c32b6a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_session_ids(cre_line : list, imaging_depths : list, stimuli : list):\n",
    "    '''\n",
    "    Get lists of session_ids matching query parameters, grouped by cortical region\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cre_line :  list\n",
    "            Array of cre_lines to query\n",
    "    imaging_depths : list\n",
    "            Array of imaging_depths to query\n",
    "    stimuli : list\n",
    "            Array of stimuli to query\n",
    "    Returns\n",
    "    -------\n",
    "    session_ids : Dictionary\n",
    "            A Dictionary indexed by targeted_areas, coantaining arrays of matching sessions_ids\n",
    "    '''\n",
    "    session_ids = {}\n",
    "    \n",
    "    for area in boc.get_all_targeted_structures():\n",
    "        exps = pd.DataFrame(boc.get_experiment_containers(\n",
    "            targeted_structures=[area], cre_lines=cre_line, imaging_depths=imaging_depth\n",
    "        ))\n",
    "        experiment_container_ids = exps.id.to_numpy()\n",
    "        sessions = boc.get_ophys_experiments(\n",
    "            experiment_container_ids=experiment_container_ids, stimuli=stimuli\n",
    "        )\n",
    "        \n",
    "        session_ids[area] = [sessions[i]['id'] for i in range(len(sessions))]\n",
    "    \n",
    "    return session_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f10033ef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tables(data_set):\n",
    "    '''\n",
    "    Return the stimulus table and events table, clipped to the duration of the stimulus\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_set : allensdk.core.brain_observatory_nwb_data_set.BrainObservatoryNwbDataSet\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    stim_table : pandas DataFrame\n",
    "            Dataframe containing stimulus information for each time step\n",
    "    events : array_like\n",
    "            2-D array of event values where events[n,m] is the event of cell n at time m\n",
    "    '''\n",
    "    stim_table = data_set.get_stimulus_table('natural_scenes')\n",
    "    \n",
    "    stim_start = stim_table.start.min()\n",
    "    stim_end = stim_table.end.max()+1\n",
    "    \n",
    "    events = boc.get_ophys_experiment_events(ophys_experiment_id=session_id)\n",
    "    events = events[:, stim_start:stim_end]\n",
    "    \n",
    "    stim_table.end = stim_table.end - stim_start\n",
    "    stim_table.start = stim_table.start - stim_start\n",
    "    \n",
    "    return stim_table, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6e2cc40",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_trial_respones(stim_table, events, axis : int = 1):\n",
    "    '''\n",
    "    Computes the average event value over the duration of each trial\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stim_table : pandas DataFrame\n",
    "            Dataframe containing stimulus information for each time step\n",
    "    events : array_like\n",
    "            2-D array of event values where events[n,m] is the event of cell n at time m\n",
    "    axis : int, optional\n",
    "            axis across which to average, default is 1\n",
    "    Returns\n",
    "    -------\n",
    "    trial_responses : array_like\n",
    "            2-D array of average event values where trial_responses[n,m]\n",
    "            is the average event value of cell n for trial m\n",
    "    '''\n",
    "    averaging_indices = stim_table.end.to_numpy()\n",
    "    cum_events = events.cumsum(axis=1)[:,averaging_indices]\n",
    "    trial_sums = np.c_[cum_events[:,0] ,np.diff(cum_events, axis=1)]\n",
    "    trial_responses = trial_sums/(stim_table.end.to_numpy() - stim_table.start.to_numpy() + 1)\n",
    "    \n",
    "    return trial_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80c793aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_outlier_trials(trial_responses, z_score : float = 3.):\n",
    "    '''\n",
    "    Compute outlying trials based on symmetric z-score\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trial_responses : pandas DataFrame\n",
    "            Dataframe containing stimulus information for each time step\n",
    "    z_score : float, optional\n",
    "            z_score used to determine outliers with |p| > z_score, default is 3.0\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    outliers : array_like\n",
    "            1-D array of trial indices corresponding to outliers\n",
    "    '''\n",
    "    trial_responses_df = pd.DataFrame(trial_responses.mean(axis=0))\n",
    "    # Calculate the Z-score for each data point\n",
    "    z_scores = trial_responses_df.apply(zscore)\n",
    "    # Identify rows with any outlier (Z-score > 3 or Z-score < -3)\n",
    "    outliers = (trial_responses_df[(z_scores > z_score) | (z_scores < -z_score)].to_numpy() > 0).nonzero()[0]\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1fefb977",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_stimulus_responses(trial_responses, stim_table, group_by : str, outliers = np.empty(0)):\n",
    "    '''\n",
    "    Computes the average trial_response for each value of the stimulus\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trial_responses : pandas DataFrame\n",
    "            Dataframe containing stimulus information for each time step\n",
    "    outliers : array_like\n",
    "            1-D array of trial indices corresponding to outliers, default is empty\n",
    "    stim_table : pandas DataFrame\n",
    "            Dataframe containing stimulus information for each time step\n",
    "    sort_by : str\n",
    "            Column name in stim_table used for grouping stimulus values for averaging\n",
    "    Returns\n",
    "    -------\n",
    "    stimulus_responses : array_like\n",
    "            2-D array of average trial_response values where stimulus_responses[n,m]\n",
    "            is the average trial_response value of cell n stimulus m\n",
    "    '''\n",
    "    trial_responses = np.delete(trial_responses, outliers, axis=1)\n",
    "    \n",
    "    frames = stim_table[group_by].to_numpy()\n",
    "    frames = np.delete(frames, outliers)\n",
    "    \n",
    "    sorting_indices = np.argsort(frames)\n",
    "    sorted_events = trial_responses[:,sorting_indices]\n",
    "    \n",
    "    num_trials_per_stim = np.fromiter(collections.Counter(np.sort(frames)).values(), dtype=float)\n",
    "    averaging_indices = num_trials_per_stim.cumsum().astype('int') - 1\n",
    "    \n",
    "    cum_trial_responses = sorted_events.cumsum(axis=1)[:,averaging_indices]\n",
    "    stimulus_responses = np.c_[cum_trial_responses[:,0] ,np.diff(cum_trial_responses, axis=1)]/num_trials_per_stim\n",
    "    \n",
    "    return stimulus_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17296658",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PCA(stimulus_responses):\n",
    "    '''\n",
    "    Computes principle components using eigenvalue decomposition\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stimulus_responses : array_like\n",
    "            2-D array of average trial_response values where stimulus_responses[n,m]\n",
    "            is the average trial_response value of cell n stimulus m\n",
    "                        \n",
    "    Returns\n",
    "    -------\n",
    "    D : array_like\n",
    "            1_D array of eigenvalues, each repeated according to its multiplicity.\n",
    "    U : array_like\n",
    "            The unit eigenvectors, where U[:,n] is the eigenvector corresponding eigenvalue D[n]\n",
    "    '''\n",
    "    mu = np.mean(stimulus_responses,axis=0)\n",
    "    stimulus_responses_centered = stimulus_responses - mu\n",
    "    cov = np.cov(stimulus_responses_centered.T)\n",
    "    \n",
    "    # perform the eigendecomposition of the data covariance\n",
    "    D, U = np.linalg.eig(cov) # D = vector of eigenvalues, U = eigenvectors matrix\n",
    "\n",
    "    # make sure the eigenvalues are sorted (in descending order)\n",
    "    indx = np.argsort(D)[::-1]\n",
    "    D = D[indx]\n",
    "\n",
    "    # arrange the eigenvectors according to the magnitude of the eigenvalues\n",
    "    U = U[:,indx]\n",
    "    \n",
    "    return D, U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "783dacc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dimensionality(D : np.ndarray):\n",
    "    '''\n",
    "    Computes number of dimensions required to explain required_variance\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    D : array_like\n",
    "        1_D array of eigenvalues, each repeated according to its multiplicity.\n",
    "    Returns\n",
    "    -------\n",
    "    dimension : float\n",
    "        Dimension of the system computed according to \n",
    "    '''\n",
    "    D = np.real(D)\n",
    "#     dimension = (D.sum()**2) / (D @ D)\n",
    "    \n",
    "    explained_vars = D.cumsum() / D.sum()\n",
    "    dimension = bisect.bisect_right(explained_vars, 0.95)\n",
    "    return dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7d2d23c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_dimensions_by_region(dimensionality : dict, error_bar = 'se'):\n",
    "    '''\n",
    "    Plots dimensionality histogram by cortical region, with error bars,\n",
    "    sorted by height in reverse order\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dimensionality : dict\n",
    "        A dictionary who's keys are visual regions (strings) and values are\n",
    "        lists containing inate dimensions of neural spaces within that region\n",
    "    error_bar : string, (string, number) tuple, callable or None\n",
    "        Name of errorbar method (either “ci”, “pi”, “se”, or “sd”), or a tuple\n",
    "        with a method name and a level parameter, or a function that maps from \n",
    "        a vector to a (min, max) interval, or None to hide errorbar\n",
    "    kernel : str\n",
    "        Name of kernel used for PCA, used for the title\n",
    "    '''\n",
    "    \n",
    "    dimensionality = dict(sorted(dimensionality.items(), key=lambda x: np.mean(x[1]), reverse=True))\n",
    "    \n",
    "    colours = sns.color_palette(\"hls\", 6)\n",
    "    areas = ['VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISrl']\n",
    "    \n",
    "    palette = [colours[areas.index(area)] for area in dimensionality.keys()]\n",
    "    \n",
    "    sns.barplot(dimensionality, errorbar=(error_bar), capsize=.4, linewidth=2.5, palette=palette)\n",
    "    plt.title(f\"Dimensionality : 0.95 Variance\")\n",
    "    plt.savefig(f\"dimensionality_pv.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "027d3d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boc = init_boc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01b12f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boc.get_all_cre_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b22b2742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cre_line = boc.get_all_cre_lines()[0:2] # 'Cux2-CreERT2', 'Emx1-IRES-Cre''\n",
    "# cre_line = [boc.get_all_cre_lines()[x] for x in [5,10,12]]\n",
    "imaging_depth = boc.get_all_imaging_depths() # 175 - 250\n",
    "stimulus = ['natural_scenes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "576439cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_ids = get_session_ids(cre_line, imaging_depth, stimulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4fe78451",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:37<00:00,  4.87s/it]\n",
      "100%|██████████| 14/14 [00:53<00:00,  3.84s/it]\n",
      "100%|██████████| 19/19 [01:37<00:00,  5.14s/it]\n",
      "100%|██████████| 26/26 [02:20<00:00,  5.42s/it]\n",
      "100%|██████████| 17/17 [01:08<00:00,  4.02s/it]\n",
      "100%|██████████| 21/21 [01:37<00:00,  4.62s/it]\n"
     ]
    }
   ],
   "source": [
    "dimensionality = {}\n",
    "for area in session_ids.keys():\n",
    "    dimensions = []\n",
    "    for session_id in tqdm(session_ids[area]):\n",
    "        data_set = boc.get_ophys_experiment_data(ophys_experiment_id=session_id)\n",
    "        stim_table, events = get_tables(data_set)\n",
    "        trial_responses = get_trial_respones(stim_table, events)\n",
    "        outliers = get_outlier_trials(trial_responses)\n",
    "        stimulus_responses = get_stimulus_responses(trial_responses, stim_table, group_by='frame', outliers=outliers)\n",
    "        D, U = PCA(stimulus_responses)\n",
    "        dimension = get_dimensionality(D)\n",
    "        dimensions.append(dimension)\n",
    "    dimensionality[area] = dimensions\n",
    "plot_dimensions_by_region(dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52d05a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open a file and use dump() \n",
    "# with open('dimensionality_excitatory_2.pkl', 'wb') as file: \n",
    "#     # A new file will be created \n",
    "#     pickle.dump(dimensionality, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4fc8b3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"330\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#db5f57;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#d3db57;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#57db5f;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#57d3db;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#5f57db;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#db57d3;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.86, 0.3712, 0.33999999999999997),\n",
       " (0.8287999999999999, 0.86, 0.33999999999999997),\n",
       " (0.33999999999999997, 0.86, 0.3712),\n",
       " (0.33999999999999997, 0.8287999999999999, 0.86),\n",
       " (0.3712, 0.33999999999999997, 0.86),\n",
       " (0.86, 0.33999999999999997, 0.8287999999999999)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.color_palette(\"hls\", 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
